{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-26T10:52:04.149638Z",
     "start_time": "2018-03-26T10:50:58.109179Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Loading data done.\n",
      "Drop columns: \n",
      "['item_category_0']\n",
      "Current category columns: \n",
      "['item_category_1', 'item_category_2', 'item_property_0', 'item_property_1', 'item_property_2']\n",
      "\n",
      " Extracting item category/property done.\n",
      "\n",
      " Current category columns: \n",
      "['item_category_1', 'item_category_2', 'item_property_0', 'item_property_1', 'item_property_2', 'predict_category_0', 'predict_category_1', 'predict_category_2', 'predict_property_0', 'predict_property_1', 'predict_property_2']\n",
      "\n",
      " Extracting predict category/property done.\n",
      "\n",
      "Add hour/category_hit/count features done.\n",
      "category columns: \n",
      "['item_category_1', 'item_category_2', 'item_property_0', 'item_property_1', 'item_property_2', 'predict_category_0', 'predict_category_1', 'predict_category_2', 'predict_category_0_hit_0', 'predict_category_1_hit_0', 'predict_category_2_hit_0', 'item_id', 'user_id', 'shop_id', 'item_brand_id', 'item_city_id', 'item_category_list', 'item_price_level', 'item_sales_level', 'item_collected_level', 'item_pv_level', 'user_gender_id', 'user_age_level', 'user_occupation_id', 'user_star_level', 'shop_review_num_level', 'shop_star_level', 'context_page_id']\n",
      "numeric columns: \n",
      "['hour', 'count_item_property_0_item_id', 'count_item_property_1_item_id', 'count_item_property_2_item_id', 'count_item_brand_id_item_id', 'count_item_city_id_item_id', 'count_item_price_level_item_id', 'count_item_sales_level_item_id', 'count_item_collected_level_item_id', 'count_item_pv_level_item_id', 'count_user_gender_id_user_id', 'count_user_age_level_user_id', 'count_user_occupation_id_user_id', 'count_user_star_level_user_id', 'count_shop_review_num_level_shop_id', 'count_shop_star_level_shop_id', 'shop_review_positive_rate', 'shop_score_service', 'shop_score_delivery', 'shop_score_description']\n",
      "instance_id                              int64\n",
      "item_price_level                         int64\n",
      "item_sales_level                         int64\n",
      "item_collected_level                     int64\n",
      "item_pv_level                            int64\n",
      "user_gender_id                           int64\n",
      "user_age_level                           int64\n",
      "user_occupation_id                       int64\n",
      "user_star_level                          int64\n",
      "context_page_id                          int64\n",
      "shop_review_num_level                    int64\n",
      "shop_review_positive_rate              float64\n",
      "shop_star_level                          int64\n",
      "shop_score_service                     float64\n",
      "shop_score_delivery                    float64\n",
      "shop_score_description                 float64\n",
      "is_trade                                 int64\n",
      "hour                                     int64\n",
      "predict_category_0_hit_0                 int32\n",
      "predict_category_1_hit_0                 int32\n",
      "predict_category_2_hit_0                 int32\n",
      "count_item_property_0_item_id            int64\n",
      "count_item_property_1_item_id            int64\n",
      "count_item_property_2_item_id            int64\n",
      "count_item_brand_id_item_id              int64\n",
      "count_item_city_id_item_id               int64\n",
      "count_item_price_level_item_id           int64\n",
      "count_item_sales_level_item_id           int64\n",
      "count_item_collected_level_item_id       int64\n",
      "count_item_pv_level_item_id              int64\n",
      "count_user_gender_id_user_id             int64\n",
      "count_user_age_level_user_id             int64\n",
      "count_user_occupation_id_user_id         int64\n",
      "count_user_star_level_user_id            int64\n",
      "count_shop_review_num_level_shop_id      int64\n",
      "count_shop_star_level_shop_id            int64\n",
      "item_id                                  int64\n",
      "user_id                                  int64\n",
      "shop_id                                  int64\n",
      "item_brand_id                            int64\n",
      "item_city_id                             int64\n",
      "item_category_list                       int64\n",
      "item_category_1                          int64\n",
      "item_category_2                          int64\n",
      "item_property_0                          int64\n",
      "item_property_1                          int64\n",
      "item_property_2                          int64\n",
      "predict_category_0                       int64\n",
      "predict_category_1                       int64\n",
      "predict_category_2                       int64\n",
      "dtype: object\n",
      "\n",
      " Type conversion done. \n",
      "\n",
      " Re-sort columns done.\n",
      "instance_id 0\n",
      "n_hour 0\n",
      "n_count_item_property_0_item_id 0\n",
      "n_count_item_property_1_item_id 0\n",
      "n_count_item_property_2_item_id 0\n",
      "n_count_item_brand_id_item_id 0\n",
      "n_count_item_city_id_item_id 0\n",
      "n_count_item_price_level_item_id 0\n",
      "n_count_item_sales_level_item_id 0\n",
      "n_count_item_collected_level_item_id 0\n",
      "n_count_item_pv_level_item_id 0\n",
      "n_count_user_gender_id_user_id 0\n",
      "n_count_user_age_level_user_id 0\n",
      "n_count_user_occupation_id_user_id 0\n",
      "n_count_user_star_level_user_id 0\n",
      "n_count_shop_review_num_level_shop_id 0\n",
      "n_count_shop_star_level_shop_id 0\n",
      "n_shop_review_positive_rate 7\n",
      "n_shop_score_service 59\n",
      "n_shop_score_delivery 59\n",
      "n_shop_score_description 59\n",
      "c_item_category_1 0\n",
      "c_item_category_2 0\n",
      "c_item_property_0 0\n",
      "c_item_property_1 0\n",
      "c_item_property_2 0\n",
      "c_predict_category_0 0\n",
      "c_predict_category_1 0\n",
      "c_predict_category_2 0\n",
      "c_predict_category_0_hit_0 0\n",
      "c_predict_category_1_hit_0 0\n",
      "c_predict_category_2_hit_0 0\n",
      "c_item_id 0\n",
      "c_user_id 0\n",
      "c_shop_id 0\n",
      "c_item_brand_id 0\n",
      "c_item_city_id 0\n",
      "c_item_category_list 0\n",
      "c_item_price_level 0\n",
      "c_item_sales_level 913\n",
      "c_item_collected_level 0\n",
      "c_item_pv_level 0\n",
      "c_user_gender_id 12902\n",
      "c_user_age_level 964\n",
      "c_user_occupation_id 964\n",
      "c_user_star_level 964\n",
      "c_shop_review_num_level 0\n",
      "c_shop_star_level 0\n",
      "c_context_page_id 0\n",
      "\n",
      " Checking missing values done.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import time\n",
    "import numba\n",
    "import os,sys\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "## load data\n",
    "def LoadData(InputDir):\n",
    "    \"\"\"\"\"\"\n",
    "    ## load raw data\n",
    "    data = {\n",
    "        'train': pd.read_csv('%s/round1_ijcai_18_train_20180301.txt' % InputDir, sep= ' '),\n",
    "        'test': pd.read_csv('%s/round1_ijcai_18_test_a_20180301.txt' % InputDir, sep= ' '),\n",
    "    }\n",
    "    return data\n",
    "\n",
    "DataBaseDir = '../../data'\n",
    "DataSet = LoadData('%s/raw' % DataBaseDir)\n",
    "for mod in ['train', 'test']:\n",
    "    DataSet[mod]['context_timestamp'] = DataSet[mod]['context_timestamp'].apply(lambda x: datetime.datetime.fromtimestamp(x))\n",
    "    DataSet[mod] = DataSet[mod].sort_values(by= 'context_timestamp')\n",
    "print('\\n Loading data done.')\n",
    "## extract item category/property features\n",
    "category_columns = []\n",
    "numeric_columns = []\n",
    "@numba.jit\n",
    "def SplitItemCategoryProperty(colvals):\n",
    "    \"\"\"\"\"\"\n",
    "    n = len(colvals)\n",
    "    result = np.empty((n, 3), dtype= 'object')\n",
    "    for i in range(n):\n",
    "        cate_list = colvals[i].split(';')\n",
    "        for j in range(3):\n",
    "            if(j < len(cate_list)):\n",
    "                if(cate_list[j] == '-1'):\n",
    "                    result[i, j] = '-1'\n",
    "                else:\n",
    "                    result[i, j] = cate_list[j]\n",
    "            else:\n",
    "                result[i, j] = '-1'\n",
    "    return result\n",
    "\n",
    "item_category_property_columns = {\n",
    "    'item_category_list': ['item_category_0', 'item_category_1', 'item_category_2'],\n",
    "    'item_property_list': ['item_property_0', 'item_property_1', 'item_property_2']\n",
    "}\n",
    "drop_item_category_property_columns = {\n",
    "    'item_category_list': set(),\n",
    "    'item_property_list': set()\n",
    "}\n",
    "for k in item_category_property_columns.keys():\n",
    "    for mod in ['train', 'test']:\n",
    "        tmp = SplitItemCategoryProperty(DataSet[mod][k].values) \n",
    "        tmpdf = pd.DataFrame(data= tmp, index= DataSet[mod].index, columns= item_category_property_columns[k])\n",
    "        DataSet[mod] = pd.concat([DataSet[mod], tmpdf], axis= 1, ignore_index= False)\n",
    "        for col in item_category_property_columns[k]:\n",
    "            if(len(DataSet[mod][col].value_counts()) == 1):\n",
    "                drop_item_category_property_columns[k].add(col)\n",
    "# drop unique-value columns\n",
    "for k in drop_item_category_property_columns.keys():\n",
    "    if(len(drop_item_category_property_columns[k]) > 0):\n",
    "        for mod in ['train', 'test']:\n",
    "            DataSet[mod].drop(list(drop_item_category_property_columns[k]), axis= 1, inplace= True)\n",
    "        print('Drop columns: ')\n",
    "        print(list(drop_item_category_property_columns[k]))\n",
    "        for c in drop_item_category_property_columns[k]:\n",
    "            item_category_property_columns[k].remove(c)\n",
    "# update category columns\n",
    "for k in item_category_property_columns.keys():\n",
    "    category_columns.extend(item_category_property_columns[k])\n",
    "print('Current category columns: ')\n",
    "print(category_columns)\n",
    "print('\\n Extracting item category/property done.')\n",
    "\n",
    "## extract predict category/property features\n",
    "@numba.jit\n",
    "def SplitPredictCategoryProperty(colvals):\n",
    "    ''''''\n",
    "    n = len(colvals)\n",
    "    result = np.empty((n, 6), dtype= 'object')\n",
    "    for i in range(n):\n",
    "        cate_prop_list = colvals[i].split(';')\n",
    "        for j in range(3):\n",
    "            if((j < len(cate_prop_list)) and (cate_prop_list[j] != '-1')):\n",
    "                cate_prop_pair = cate_prop_list[j].split(':')\n",
    "                if(len(cate_prop_pair) != 2):\n",
    "                    print(cate_prop_list[j])\n",
    "                if((cate_prop_pair[0] is None) or (cate_prop_pair[0] == '-1')):\n",
    "                    result[i, j] = '-1'\n",
    "                else:\n",
    "                    result[i, j] = cate_prop_pair[0]\n",
    "                if((cate_prop_pair[1] is None) or (cate_prop_pair[1] == '-1')):\n",
    "                    result[i, j + 3] = '-1'\n",
    "                else:\n",
    "                    result[i, j + 3] = cate_prop_pair[1]\n",
    "            else:\n",
    "                result[i, j] = '-1'\n",
    "                result[i, j + 3] = '-1'\n",
    "    return result\n",
    "\n",
    "predict_category_property_columns = ['predict_category_0', 'predict_category_1', 'predict_category_2', \n",
    "                                    'predict_property_0', 'predict_property_1', 'predict_property_2']\n",
    "drop_predict_category_property_columns = set()\n",
    "for mod in ['train', 'test']:\n",
    "    tmp = SplitPredictCategoryProperty(DataSet[mod]['predict_category_property'].values) \n",
    "    tmpdf = pd.DataFrame(data= tmp, index= DataSet[mod].index, columns= predict_category_property_columns)\n",
    "    DataSet[mod] = pd.concat([DataSet[mod], tmpdf], axis= 1, ignore_index= False)\n",
    "    for col in predict_category_property_columns:\n",
    "        if(len(DataSet[mod][col].value_counts()) == 1):\n",
    "            drop_predict_category_property_columns.add(col)          \n",
    "# drop unique-value columns\n",
    "if(len(drop_predict_category_property_columns) > 0):\n",
    "    for mod in ['train', 'test']:\n",
    "        DataSet[mod].drop(list(drop_predict_category_property_columns), axis= 1, inplace= True)\n",
    "    print('\\n Drop columns: ')\n",
    "    print(list(drop_predict_category_property_columns))\n",
    "    for c in drop_predict_category_property_columns:\n",
    "        predict_category_property_columns.remove(c)\n",
    "# update category columns\n",
    "category_columns.extend(predict_category_property_columns)\n",
    "print('\\n Current category columns: ')\n",
    "print(category_columns)\n",
    "print('\\n Extracting predict category/property done.')\n",
    "\n",
    "## hour\n",
    "for mod in ['train', 'test']:\n",
    "    DataSet[mod]['hour'] = DataSet[mod]['context_timestamp'].dt.hour ## new column, feature\n",
    "numeric_columns.append('hour')\n",
    "## category hit\n",
    "for c in predict_category_property_columns[:3]:\n",
    "    for mod in ['train', 'test']:\n",
    "        DataSet[mod]['%s_hit_0' % c] = DataSet[mod][c].apply(lambda x: (x == '7908382889764677758'))\n",
    "        DataSet[mod]['%s_hit_0' % c] = DataSet[mod]['%s_hit_0' % c].astype('int32')\n",
    "    category_columns.append('%s_hit_0' % c)\n",
    "## count\n",
    "count_dict = {\n",
    "    'item_id':  ['item_property_0', 'item_property_1', 'item_property_2', 'item_brand_id', 'item_city_id', 'item_price_level', 'item_sales_level', 'item_collected_level', 'item_pv_level'],\n",
    "    'user_id':  ['user_gender_id', 'user_age_level', 'user_occupation_id', 'user_star_level'],\n",
    "    'shop_id':  ['shop_review_num_level', 'shop_star_level']\n",
    "}\n",
    "for count_id in count_dict.keys():\n",
    "    for count_key in count_dict[count_id]:\n",
    "        for mod in ['train', 'test']:\n",
    "            rec = []\n",
    "            groupped = DataSet[mod].groupby([count_key])\n",
    "            for g in groupped.groups:\n",
    "                ac = {}\n",
    "                ac[count_key] = g\n",
    "                ac['count_%s_%s' % (count_key, count_id)] = len(groupped.get_group(g)[count_id].unique())\n",
    "                rec.append(ac)\n",
    "            tmpdf = pd.DataFrame(data= rec, index= range(len(rec)))\n",
    "            DataSet[mod] = DataSet[mod].merge(tmpdf, how= 'left', on= [count_key])\n",
    "        numeric_columns.append('count_%s_%s' % (count_key, count_id))\n",
    "print('\\nAdd hour/category_hit/count features done.')\n",
    "## encode for id features\n",
    "id_cate_feat = ['item_id', 'user_id', 'shop_id', 'item_brand_id', 'item_city_id', 'item_category_list']\n",
    "category_columns.extend(id_cate_feat)\n",
    "id_cate_feat.extend(item_category_property_columns['item_category_list'])\n",
    "id_cate_feat.extend(item_category_property_columns['item_property_list'])\n",
    "id_cate_feat.extend(predict_category_property_columns[:3])\n",
    "for col in id_cate_feat:\n",
    "    unique_values = list(DataSet['train'][col].unique())\n",
    "    encode_dict = dict(zip(unique_values, range(len(unique_values))))\n",
    "    for mod in ['train', 'test']:    \n",
    "        DataSet[mod]['%s_encoded' % col] = DataSet[mod][col].apply(lambda x: encode_dict.get(x, -1))\n",
    "        DataSet[mod].drop([col], axis= 1, inplace= True)\n",
    "        DataSet[mod].rename(columns= {'%s_encoded' % col: col}, inplace= True)\n",
    "\n",
    "item_cate_feat = ['item_price_level', 'item_sales_level', 'item_collected_level', 'item_pv_level']\n",
    "user_cate_feat = ['user_gender_id', 'user_age_level', 'user_occupation_id', 'user_star_level']\n",
    "shop_cate_feat = ['shop_review_num_level', 'shop_star_level']\n",
    "context_cate_feat = ['context_page_id']\n",
    "category_columns.extend(item_cate_feat)\n",
    "category_columns.extend(user_cate_feat)\n",
    "category_columns.extend(shop_cate_feat)\n",
    "category_columns.extend(context_cate_feat)\n",
    "shop_num_feat = ['shop_review_positive_rate', 'shop_score_service', 'shop_score_delivery', 'shop_score_description']\n",
    "numeric_columns.extend(shop_num_feat)\n",
    "drop_columns = ['item_property_list', 'predict_category_property', 'predict_property_0', 'predict_property_1', \n",
    "                'predict_property_2','context_id', 'context_timestamp']\n",
    "for mod in ['train', 'test']:\n",
    "    DataSet[mod].drop(drop_columns, axis= 1, inplace= True)\n",
    "category_columns = [c for c in category_columns if(c not in drop_columns)]\n",
    "numeric_columns = [c for c in numeric_columns if(c not in drop_columns)]\n",
    "print('category columns: ')\n",
    "print(category_columns)\n",
    "print('numeric columns: ')\n",
    "print(numeric_columns)\n",
    "print(DataSet['train'].dtypes)\n",
    "print('\\n Type conversion done. ')\n",
    "# tagging columns\n",
    "tagged_numeric_columns = ['n_%s' % col for col in numeric_columns]\n",
    "tagged_category_columns = ['c_%s' % col for col in category_columns]\n",
    "renamed_columns = dict(list(dict(zip(numeric_columns, tagged_numeric_columns)).items()) + list(dict(zip(category_columns, tagged_category_columns)).items()))\n",
    "# renamed_columns['instance_id'] = 'instance_id'\n",
    "for mod in ['train', 'test']:\n",
    "    DataSet[mod].rename(columns= renamed_columns, inplace= True)\n",
    "all_features= ['instance_id']\n",
    "all_features.extend(tagged_numeric_columns)\n",
    "all_features.extend(tagged_category_columns)\n",
    "print('\\n Re-sort columns done.')\n",
    "## re-sort columns\n",
    "target = 'is_trade'\n",
    "sorted_columns = ['instance_id']\n",
    "sorted_columns.append(target)\n",
    "sorted_columns.extend(tagged_numeric_columns)\n",
    "sorted_columns.extend(tagged_category_columns)\n",
    "DataSet['test'][target] = .0\n",
    "for mod in ['train', 'test']:\n",
    "    DataSet[mod] = DataSet[mod][sorted_columns]\n",
    "## checking missing values\n",
    "for col in all_features:\n",
    "    null_size = len(DataSet['train'][DataSet['train'][col] == -1])\n",
    "    print(col, null_size)\n",
    "print('\\n Checking missing values done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-26T10:52:04.154218Z",
     "start_time": "2018-03-26T10:52:04.151347Z"
    }
   },
   "outputs": [],
   "source": [
    "# ## check\n",
    "# print(DataSet['train'].columns)\n",
    "# print(len(DataSet['train']['c_item_category_list'].unique()), len(DataSet['train']))\n",
    "# #print(len(DataSet['train']['c_predict_category'].unique()), len(DataSet['train']))\n",
    "# for c in ['c_predict_category_0', 'c_predict_category_1', 'c_predict_category_2']:\n",
    "#     print(c, len(DataSet['train'][DataSet['train'][c] == '7908382889764677758']), len(DataSet['train']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-26T10:52:23.161207Z",
     "start_time": "2018-03-26T10:52:04.156077Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 0, train 382509, valid 95629\n",
      "-----------------------------------------\n",
      "0.0188649155968\n",
      "-----------------------------------------\n",
      "\n",
      "fold 1, train 382510, valid 95628\n",
      "-----------------------------------------\n",
      "0.0188674805887\n",
      "-----------------------------------------\n",
      "\n",
      "fold 2, train 382511, valid 95627\n",
      "-----------------------------------------\n",
      "0.0188674312634\n",
      "-----------------------------------------\n",
      "\n",
      "fold 3, train 382511, valid 95627\n",
      "-----------------------------------------\n",
      "0.0188674312634\n",
      "-----------------------------------------\n",
      "\n",
      "fold 4, train 382511, valid 95627\n",
      "-----------------------------------------\n",
      "0.0188674312634\n",
      "-----------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "kfold = 5\n",
    "\n",
    "OutputDir = '%s/l0' % DataBaseDir\n",
    "fold = 0\n",
    "for train_index, valid_index in StratifiedKFold(n_splits= kfold).split(DataSet['train'][all_features], DataSet['train'][target]):\n",
    "    print('fold %s, train %s, valid %s' % (fold, len(train_index), len(valid_index)))\n",
    "    FoldOutput = '%s/kfold/%s' % (OutputDir, fold)\n",
    "    if(os.path.exists(FoldOutput) == False):\n",
    "        os.makedirs(FoldOutput)\n",
    "    DataSet['train'].iloc[valid_index].to_csv('%s/valid.csv' % FoldOutput, index= False)\n",
    "    DataSet['test'].to_csv('%s/test.csv' % FoldOutput, index= False)\n",
    "    ## check\n",
    "    print('-----------------------------------------')\n",
    "    print(DataSet['train'].iloc[train_index][target].sum(axis= 0)/len(train_index))\n",
    "    print('-----------------------------------------\\n')\n",
    "    fold += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
